"""
Tareas de Celery para anÃ¡lisis asÃ­ncrono de artÃ­culos
Maneja el anÃ¡lisis individual de artÃ­culos usando OpenAI
"""

import asyncio
from typing import Dict, Any, Optional
from celery import Task
from loguru import logger

from celery_app import celery_app
from app.core.config import settings
from app.services.news_service import NewsClientError


class ArticleAnalysisTask(Task):
    """Task base para anÃ¡lisis de artÃ­culos con retry y manejo de errores"""
    
    autoretry_for = (NewsClientError, Exception,)
    retry_kwargs = {'max_retries': 3, 'countdown': 60}
    retry_backoff = True
    retry_backoff_max = 700
    retry_jitter = False
    
    def on_failure(self, exc, task_id, args, kwargs, einfo):
        """Handler de falla para logging y monitoreo"""
        logger.error(f"ðŸ’¥ Error en anÃ¡lisis de artÃ­culo {task_id}: {exc}")
        logger.debug(f"Detalles del error: {einfo}")


@celery_app.task(
    bind=True,
    name='app.tasks.article_tasks.analyze_article_async',
    base=ArticleAnalysisTask,
    queue='ai_analysis',
    rate_limit='10/m'
)
def analyze_article_async(self, article_data: Dict[str, Any], analysis_type: str = 'comprehensive') -> Dict[str, Any]:
    """
    Analizar un artÃ­culo de forma asÃ­ncrona usando OpenAI
    
    Args:
        article_data: Datos del artÃ­culo a analizar
        analysis_type: Tipo de anÃ¡lisis ('basic', 'comprehensive', 'sentiment')
        
    Returns:
        Dict con resultados del anÃ¡lisis
        
    Raises:
        NewsClientError: Si hay problemas con la API de OpenAI
    """
    import time
    start_time = time.time()
    
    try:
        logger.info(f"ðŸ” Iniciando anÃ¡lisis {analysis_type} del artÃ­culo: {article_data.get('title', 'Sin tÃ­tulo')[:50]}...")
        
        # Validar datos del artÃ­culo
        if not article_data.get('content') and not article_data.get('description'):
            raise ValueError("El artÃ­culo debe tener contenido o descripciÃ³n para analizar")
        
        # Preparar el texto a analizar
        text_to_analyze = f"""
        TÃ­tulo: {article_data.get('title', '')}
        DescripciÃ³n: {article_data.get('description', '')}
        Contenido: {article_data.get('content', '')[:2000]}...
        Fuente: {article_data.get('source_name', '')}
        """
        
        # Realizar el anÃ¡lisis segÃºn el tipo
        if analysis_type == 'basic':
            analysis_result = _perform_basic_analysis(text_to_analyze)
        elif analysis_type == 'sentiment':
            analysis_result = _perform_sentiment_analysis(text_to_analyze)
        else:  # comprehensive
            analysis_result = _perform_comprehensive_analysis(text_to_analyze)
        
        # Agregar metadata al resultado
        analysis_result.update({
            'article_id': article_data.get('id'),
            'article_url': article_data.get('url'),
            'analysis_type': analysis_type,
            'analysis_timestamp': time.time(),
            'processing_time': time.time() - start_time,
            'task_id': self.request.id,
            'status': 'completed'
        })
        
        logger.info(f"âœ… AnÃ¡lisis {analysis_type} completado en {analysis_result['processing_time']:.2f}s")
        return analysis_result
        
    except Exception as e:
        logger.error(f"âŒ Error en anÃ¡lisis de artÃ­culo: {str(e)}")
        
        # Retornar resultado de error para evitar que la tarea falle completamente
        return {
            'status': 'error',
            'error_message': str(e),
            'article_id': article_data.get('id'),
            'analysis_type': analysis_type,
            'analysis_timestamp': time.time(),
            'processing_time': time.time() - start_time,
            'task_id': self.request.id
        }


def _perform_basic_analysis(text: str) -> Dict[str, Any]:
    """Realizar anÃ¡lisis bÃ¡sico del texto"""
    try:
        if not settings.OPENAI_API_KEY:
            return _fallback_basic_analysis(text)
        
        import openai
        
        openai.api_key = settings.OPENAI_API_KEY
        
        prompt = f"""
        Analiza el siguiente artÃ­culo y proporciona un resumen bÃ¡sico y clasificaciÃ³n temÃ¡tica:
        
        {text[:1500]}
        
        Responde en formato JSON con:
        - summary: Resumen en 2-3 lÃ­neas
        - topics: Lista de 2-4 temas principales
        - category: CategorÃ­a principal (tecnologÃ­a, polÃ­tica, deportes, etc.)
        - urgency: Nivel de urgencia (baja, media, alta)
        - language: idioma detectado
        """
        
        response = openai.ChatCompletion.create(
            model=settings.OPENAI_MODEL,
            messages=[
                {"role": "system", "content": "Eres un experto analista de noticias. Responde siempre en formato JSON vÃ¡lido."},
                {"role": "user", "content": prompt}
            ],
            max_tokens=500,
            temperature=0.3
        )
        
        result_text = response.choices[0].message.content
        import json
        return json.loads(result_text)
        
    except Exception as e:
        logger.warning(f"Error en OpenAI basic analysis: {str(e)}")
        return _fallback_basic_analysis(text)


def _perform_comprehensive_analysis(text: str) -> Dict[str, Any]:
    """Realizar anÃ¡lisis comprensivo del texto"""
    try:
        if not settings.OPENAI_API_KEY:
            return _fallback_comprehensive_analysis(text)
        
        import openai
        
        openai.api_key = settings.OPENAI_API_KEY
        
        prompt = f"""
        Realiza un anÃ¡lisis comprensivo del siguiente artÃ­culo:
        
        {text[:2000]}
        
        Responde en formato JSON con:
        - summary: Resumen ejecutivo de 3-4 lÃ­neas
        - key_points: Lista de 5-7 puntos clave
        - topics: Lista de temas principales (mÃ­nimo 3)
        - category: CategorÃ­a principal
        - subcategories: Lista de subcategorÃ­as
        - sentiment: AnÃ¡lisis de sentimiento (positivo, negativo, neutral)
        - urgency: Nivel de urgencia (baja, media, alta)
        - impact_level: Nivel de impacto (local, nacional, internacional)
        - entities: Lista de entidades mencionadas (personas, organizaciones, lugares)
        - language: idioma detectado
        - reading_time_minutes: tiempo estimado de lectura
        - credibility_score: puntuaciÃ³n de credibilidad (1-10)
        """
        
        response = openai.ChatCompletion.create(
            model=settings.OPENAI_MODEL,
            messages=[
                {"role": "system", "content": "Eres un analista profesional de noticias. Responde siempre en formato JSON vÃ¡lido y preciso."},
                {"role": "user", "content": prompt}
            ],
            max_tokens=800,
            temperature=0.2
        )
        
        result_text = response.choices[0].message.content
        import json
        return json.loads(result_text)
        
    except Exception as e:
        logger.warning(f"Error en OpenAI comprehensive analysis: {str(e)}")
        return _fallback_comprehensive_analysis(text)


def _perform_sentiment_analysis(text: str) -> Dict[str, Any]:
    """Realizar anÃ¡lisis de sentimiento especÃ­fico"""
    try:
        if not settings.OPENAI_API_KEY:
            return _fallback_sentiment_analysis(text)
        
        import openai
        
        openai.api_key = settings.OPENAI_API_KEY
        
        prompt = f"""
        Realiza un anÃ¡lisis detallado de sentimiento del siguiente artÃ­culo:
        
        {text[:1500]}
        
        Responde en formato JSON con:
        - overall_sentiment: sentimiento general (positivo, negativo, neutral)
        - sentiment_score: puntuaciÃ³n de -1 a 1
        - emotional_tone: tono emocional principal
        - emotional_intensity: intensidad emocional (baja, media, alta)
        - tone_description: descripciÃ³n textual del tono
        - key_emotions: lista de emociones detectadas
        - confidence_level: nivel de confianza del anÃ¡lisis (0-100)
        - language: idioma detectado
        """
        
        response = openai.ChatCompletion.create(
            model=settings.OPENAI_MODEL,
            messages=[
                {"role": "system", "content": "Eres un experto en anÃ¡lisis de sentimiento y emociones en textos. Responde siempre en formato JSON vÃ¡lido."},
                {"role": "user", "content": prompt}
            ],
            max_tokens=400,
            temperature=0.3
        )
        
        result_text = response.choices[0].message.content
        import json
        return json.loads(result_text)
        
    except Exception as e:
        logger.warning(f"Error en OpenAI sentiment analysis: {str(e)}")
        return _fallback_sentiment_analysis(text)


# Funciones de fallback cuando OpenAI no estÃ¡ disponible
def _fallback_basic_analysis(text: str) -> Dict[str, Any]:
    """AnÃ¡lisis bÃ¡sico de fallback usando tÃ©cnicas tradicionales"""
    import re
    from collections import Counter
    
    # AnÃ¡lisis bÃ¡sico por palabras clave
    words = re.findall(r'\b\w+\b', text.lower())
    word_freq = Counter(words)
    
    # Palabras clave comunes por categorÃ­a
    categories = {
        'tecnologÃ­a': ['technology', 'tech', 'software', 'digital', 'ai', 'artificial intelligence', 'internet'],
        'polÃ­tica': ['government', 'political', 'policy', 'election', 'parliament', 'congress'],
        'economÃ­a': ['economic', 'economy', 'market', 'financial', 'business', 'trade'],
        'deportes': ['sport', 'football', 'basketball', 'soccer', 'tennis', 'olympic'],
        'salud': ['health', 'medical', 'hospital', 'disease', 'treatment', 'doctor']
    }
    
    scores = {}
    for category, keywords in categories.items():
        score = sum(word_freq.get(keyword, 0) for keyword in keywords)
        if score > 0:
            scores[category] = score
    
    main_category = max(scores, key=scores.get) if scores else 'general'
    
    # ExtracciÃ³n de puntos clave (primeras oraciones)
    sentences = re.split(r'[.!?]+', text)
    key_points = [s.strip() for s in sentences[:3] if len(s.strip()) > 20]
    
    return {
        'summary': text[:200] + '...' if len(text) > 200 else text,
        'topics': list(scores.keys())[:4],
        'category': main_category,
        'urgency': 'media',
        'language': 'es',
        'analysis_method': 'fallback'
    }


def _fallback_comprehensive_analysis(text: str) -> Dict[str, Any]:
    """AnÃ¡lisis comprensivo de fallback"""
    basic_result = _fallback_basic_analysis(text)
    
    return {
        **basic_result,
        'key_points': basic_result.get('topics', [])[:5],
        'subcategories': [],
        'sentiment': 'neutral',
        'impact_level': 'local',
        'entities': [],
        'reading_time_minutes': max(1, len(text) // 200),
        'credibility_score': 7,
        'analysis_method': 'fallback_comprehensive'
    }


def _fallback_sentiment_analysis(text: str) -> Dict[str, Any]:
    """AnÃ¡lisis de sentimiento de fallback"""
    positive_words = ['good', 'great', 'excellent', 'positive', 'success', 'win', 'achieve']
    negative_words = ['bad', 'terrible', 'negative', 'fail', 'loss', 'crisis', 'problem']
    
    text_lower = text.lower()
    pos_count = sum(1 for word in positive_words if word in text_lower)
    neg_count = sum(1 for word in negative_words if word in text_lower)
    
    if pos_count > neg_count:
        sentiment = 'positive'
        score = 0.6
    elif neg_count > pos_count:
        sentiment = 'negative'
        score = -0.6
    else:
        sentiment = 'neutral'
        score = 0.0
    
    return {
        'overall_sentiment': sentiment,
        'sentiment_score': score,
        'emotional_tone': 'neutral',
        'emotional_intensity': 'media',
        'tone_description': f'Tono {sentiment} detectado',
        'key_emotions': [sentiment],
        'confidence_level': 70,
        'language': 'es',
        'analysis_method': 'fallback_sentiment'
    }