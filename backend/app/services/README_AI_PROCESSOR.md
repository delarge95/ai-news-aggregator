# AI Processor Service

Servicio avanzado de procesamiento de noticias con OpenAI GPT que proporciona an√°lisis de sentimiento, clasificaci√≥n de temas, generaci√≥n de res√∫menes y scoring de relevancia.

## üöÄ Caracter√≠sticas Principales

### ‚úÖ Funcionalidades Implementadas

- **üìä An√°lisis de Sentimiento**: An√°lisis detallado con puntuaci√≥n de -1 a 1 y etiquetas de emoci√≥n
- **üè∑Ô∏è Clasificaci√≥n de Temas**: Clasificaci√≥n autom√°tica en 12 categor√≠as predefinidas
- **üìù Generaci√≥n de Res√∫menes**: Res√∫menes inteligentes con puntos clave
- **‚≠ê Scoring de Relevancia**: Evaluaci√≥n de relevancia basada en m√∫ltiples factores
- **üîÑ Procesamiento S√≠ncrono y As√≠ncrono**: Soporte completo para ambos modos
- **‚ö° Rate Limit Handling**: Manejo robusto de l√≠mites de API
- **üîÑ Retry Logic**: Reintentos autom√°ticos con backoff exponencial
- **üí∞ Optimizaci√≥n de Costos**: Selecci√≥n autom√°tica de modelos y c√°lculo de costos
- **üóÉÔ∏è Cache Inteligente**: Cache en memoria con TTL configurable
- **üìà Monitoreo**: Logging detallado y m√©tricas de performance
- **üîß Fallbacks**: Sistemas de respaldo para cuando OpenAI no est√° disponible

## üèóÔ∏è Arquitectura

```
ai_processor.py
‚îú‚îÄ‚îÄ RateLimitHandler          # Manejo de l√≠mites de rate
‚îú‚îÄ‚îÄ RetryHandler              # L√≥gica de reintentos
‚îú‚îÄ‚îÄ CostOptimizer             # Optimizaci√≥n de costos
‚îú‚îÄ‚îÄ CacheManager              # Gesti√≥n de cache
‚îú‚îÄ‚îÄ SentimentAnalyzer         # An√°lisis de sentimiento
‚îú‚îÄ‚îÄ TopicClassifier           # Clasificaci√≥n de temas
‚îú‚îÄ‚îÄ Summarizer               # Generaci√≥n de res√∫menes
‚îú‚îÄ‚îÄ RelevanceScorer          # Scoring de relevancia
‚îú‚îÄ‚îÄ ComprehensiveAnalyzer    # Analizador unificado
‚îî‚îÄ‚îÄ Factory Functions        # Funciones de creaci√≥n
```

## üì¶ Instalaci√≥n y Configuraci√≥n

### Dependencias

El sistema requiere las siguientes dependencias (ya incluidas en requirements.txt):

```bash
# OpenAI SDK
openai>=1.3.7

# Utilidades de async y concurrencia
asyncio
concurrent.futures

# Procesamiento de texto
re
hashlib
json
```

### Variables de Entorno

```bash
export OPENAI_API_KEY="tu-api-key-aqui"
```

## üéØ Uso B√°sico

### 1. Crear Analizador Comprehensivo

```python
from app.services.ai_processor import create_ai_processor

# Crear instancia con configuraci√≥n por defecto
analyzer = create_ai_processor(openai_api_key="tu-api-key")

# Con configuraci√≥n personalizada
analyzer = create_ai_processor(
    openai_api_key="tu-api-key",
    default_model="gpt-3.5-turbo",
    requests_per_minute=50,
    cache_ttl=3600  # 1 hora
)
```

### 2. An√°lisis Completo de Art√≠culo

```python
article = {
    "id": "article_001",
    "title": "Nueva tecnolog√≠a de IA revoluciona la industria m√©dica",
    "content": "Una revolucionaria tecnolog√≠a de inteligencia artificial...",
    "description": "Nueva IA desarrollada por MIT mejora el diagn√≥stico m√©dico"
}

# An√°lisis s√≠ncrono
result = analyzer.analyze_article(
    article_id=article["id"],
    content=article["title"] + " " + article["content"],
    user_preferences={
        "technology": 0.8,
        "health": 0.9,
        "science": 0.7
    },
    max_summary_words=150
)

# Acceder a resultados
print(f"Sentimiento: {result.sentiment.sentiment.value}")
print(f"Tema: {result.topic.primary_topic.value}")
print(f"Relevancia: {result.relevance.relevance_score:.2f}")
print(f"Costo total: ${result.total_cost:.4f}")
```

### 3. An√°lisis As√≠ncrono

```python
import asyncio

async def analyze_news_batch():
    articles = [
        {"id": "tech_001", "title": "Apple lanza nuevo iPhone", "content": "..."},
        {"id": "pol_001", "title": "Elecciones 2024", "content": "..."},
        {"id": "health_001", "title": "Nueva vacuna COVID-19", "content": "..."}
    ]
    
    results, errors = await analyzer.batch_analyze_async(
        articles=articles,
        max_concurrent=3
    )
    
    print(f"An√°lisis completados: {len(results)}")
    print(f"Errores: {len(errors)}")

# Ejecutar
asyncio.run(analyze_news_batch())
```

## üîß Uso Avanzado

### Analizadores Individuales

```python
from app.services.ai_processor import (
    SentimentAnalyzer, TopicClassifier, Summarizer, RelevanceScorer
)

# An√°lisis de sentimiento individual
sentiment_analyzer = SentimentAnalyzer(openai_api_key="tu-api-key")
sentiment_result = sentiment_analyzer.analyze_sentiment(text)

# Clasificaci√≥n de tema individual
topic_classifier = TopicClassifier(openai_api_key="tu-api-key")
topic_result = topic_classifier.classify_topic(text)

# Resumen individual
summarizer = Summarizer(openai_api_key="tu-api-key")
summary_result = summarizer.summarize(text, max_words=100)

# Scoring de relevancia individual
relevance_scorer = RelevanceScorer(openai_api_key="tu-api-key")
relevance_result = relevance_scorer.score_relevance(
    text, 
    user_preferences={"economy": 0.9}
)
```

### Configuraciones por Entorno

```python
# Desarrollo (econ√≥mico)
dev_analyzer = create_ai_processor(
    default_model="gpt-3.5-turbo",
    requests_per_minute=30,
    cache_ttl=7200  # 2 horas
)

# Producci√≥n (robusto)
prod_analyzer = create_ai_processor(
    default_model="gpt-4",
    requests_per_minute=60,
    cache_ttl=3600  # 1 hora
)

# Tiempo real (r√°pido)
realtime_analyzer = create_ai_processor(
    default_model="gpt-3.5-turbo",
    requests_per_minute=100,
    cache_ttl=1800  # 30 minutos
)
```

## üìä Tipos de Resultados

### SentimentResult
```python
{
    "sentiment": SentimentType.POSITIVE,  # POSITIVE, NEGATIVE, NEUTRAL, MIXED
    "sentiment_score": 0.75,              # -1 a 1
    "confidence": 0.85,                   # 0 a 1
    "emotion_tags": ["optimism", "hope"], # Lista de emociones
    "processing_time": 1.2,              # segundos
    "cost": 0.002,                       # costo en d√≥lares
    "model": "gpt-3.5-turbo"
}
```

### TopicResult
```python
{
    "primary_topic": TopicCategory.TECHNOLOGY,
    "topic_probability": 0.92,           # 0 a 1
    "secondary_topics": [                # Top 3 temas secundarios
        (TopicCategory.SCIENCE, 0.65),
        (TopicCategory.HEALTH, 0.43)
    ],
    "topic_keywords": ["AI", "machine learning", "technology"],
    "processing_time": 0.8,
    "cost": 0.001
}
```

### SummaryResult
```python
{
    "summary": "Resumen conciso del art√≠culo...",
    "key_points": [
        "Punto clave 1",
        "Punto clave 2", 
        "Punto clave 3"
    ],
    "word_count": 120,
    "reading_time_minutes": 0.6,         # basado en 200 WPM
    "processing_time": 2.1,
    "cost": 0.008
}
```

### RelevanceResult
```python
{
    "relevance_score": 0.78,             # 0 a 1
    "importance_score": 0.85,            # 0 a 1
    "trending_score": 0.72,              # 0 a 1
    "relevance_factors": {
        "current_events": 0.8,
        "topic_importance": 0.9,
        "celebrity_involvement": 0.3,
        "financial_impact": 0.6
    },
    "processing_time": 1.5,
    "cost": 0.003
}
```

## üí∞ Gesti√≥n de Costos

### Precios por Token (USD)
- **GPT-3.5-turbo**: $0.5/1M tokens entrada, $1.5/1M tokens salida
- **GPT-4**: $30/1M tokens entrada, $60/1M tokens salida

### Selecci√≥n Autom√°tica de Modelos
```python
models = {
    "sentiment": "gpt-3.5-turbo",           # Tareas simples
    "topic_classification": "gpt-3.5-turbo", # Tareas simples  
    "summary": "gpt-4",                      # Tareas complejas
    "relevance": "gpt-3.5-turbo"             # Tareas simples
}
```

### C√°lculo de Costos
```python
# Funci√≥n de utilidad
from app.services.ai_processor import analyze_cost_breakdown

results = [analysis_result_1, analysis_result_2, ...]
cost_breakdown = analyze_cost_breakdown(results)

print(f"Costo total: ${cost_breakdown['total_cost']:.4f}")
print(f"Costo promedio: ${cost_breakdown['average_cost']:.4f}")
```

## ‚ö° Rate Limiting

### Configuraci√≥n de L√≠mites
```python
analyzer = create_ai_processor(
    requests_per_minute=60,    # L√≠mite por minuto
    requests_per_day=10000     # L√≠mite por d√≠a
)
```

### Comportamiento Autom√°tico
- ‚úÖ Espera autom√°tica cuando se alcanza el l√≠mite
- ‚úÖ Limpieza autom√°tica de historial antiguo
- ‚úÖ C√°lculo din√°mico de tiempo de espera
- ‚úÖ Monitoreo en logs

## üîÑ Retry Logic

### Configuraci√≥n
```python
retry_handler = RetryHandler(
    max_retries=3,        # M√°ximo n√∫mero de reintentos
    base_delay=1.0,       # Delay inicial (segundos)
    max_delay=60.0        # Delay m√°ximo (segundos)
)
```

### Backoff Exponencial
```
Intento 1: wait 1s
Intento 2: wait 2s  
Intento 3: wait 4s
Intento 4: wait 8s (m√°ximo)
```

## üóÉÔ∏è Sistema de Cache

### Configuraci√≥n
```python
cache_manager = CacheManager(ttl_seconds=3600)  # 1 hora por defecto
```

### Caracter√≠sticas
- **TTL configurable**: Tiempo de vida personalizable
- **Generaci√≥n de claves**: Hash MD5 de contenido + tipo de an√°lisis
- **Limpieza autom√°tica**: Elimina entradas expiradas
- **L√≠mite de memoria**: Control de tama√±o de cache

## üß™ Testing

### Ejecutar Tests B√°sicos
```bash
python app/services/test_ai_processor.py
```

### Ejecutar Tests Completos con Pytest
```bash
pytest app/services/test_ai_processor.py -v
```

### Tests Incluidos
- ‚úÖ Inicializaci√≥n de componentes
- ‚úÖ Preparaci√≥n y limpieza de contenido
- ‚úÖ Estimaci√≥n de tokens
- ‚úÖ Fallbacks sin API key
- ‚úÖ An√°lisis s√≠ncrono y as√≠ncrono
- ‚úÖ C√°lculo de scores combinados
- ‚úÖ An√°lisis de costos
- ‚úÖ Tests de integraci√≥n

## üìù Ejemplos Completos

### Ejemplo con Manejo de Errores
```python
try:
    result = analyzer.analyze_article("article_001", content)
    print(f"An√°lisis exitoso: {result.combined_score:.2f}")
    
except RateLimitError as e:
    print(f"L√≠mite de rate alcanzado: {e}")
    # Implementar estrategia de reintento
    
except Exception as e:
    print(f"Error en an√°lisis: {e}")
    # Usar fallback local
```

### Ejemplo de An√°lisis en Tiempo Real
```python
async def real_time_analysis():
    articles_stream = get_news_stream()  # Generator de art√≠culos
    
    semaphore = asyncio.Semaphore(5)  # M√°ximo 5 concurrentes
    async with semaphore:
        for article in articles_stream:
            try:
                result = await analyzer.analyze_article_async(
                    article["id"], 
                    article["content"],
                    max_summary_words=75  # Res√∫menes m√°s cortos
                )
                yield result
                
            except Exception as e:
                logger.error(f"Error procesando {article['id']}: {e}")
                continue
```

## üîß Configuraci√≥n de Producci√≥n

### Variables de Entorno
```bash
# OpenAI
OPENAI_API_KEY=sk-...

# Rate Limits
AI_REQUESTS_PER_MINUTE=60
AI_REQUESTS_PER_DAY=10000

# Cache
AI_CACHE_TTL=3600  # 1 hora

# Logging
LOG_LEVEL=INFO
```

### Configuraci√≥n de Celery (Opcional)
```python
# Tareas en background
from app.services.ai_processor import celery_app

# Enviar an√°lisis a queue
celery_app.send_task(
    'analyze_article_async',
    args=['article_id', 'content'],
    kwargs={'openai_api_key': os.getenv('OPENAI_API_KEY')}
)
```

## üìà Monitoreo y M√©tricas

### Logs Incluidos
- ‚úÖ Inicializaci√≥n de componentes
- ‚úÖ Rate limit warnings
- ‚úÖ Retry attempts
- ‚úÖ Resultados de an√°lisis
- ‚úÖ C√°lculos de costos
- ‚úÖ Errores y fallbacks

### M√©tricas Disponibles
- Tiempo de procesamiento
- Tokens utilizados
- Costos por an√°lisis
- Tasa de aciertos del cache
- Distribuci√≥n de temas
- Patrones de sentimiento

## ü§ù Compatibilidad

### Backward Compatibility
- ‚úÖ Mantiene compatibilidad con el `AIProcessor` legacy
- ‚úÖ M√©todos heredados marcados como deprecated
- ‚úÖ Estructuras de datos compatibles
- ‚úÖ Importaciones existentes funcionan

### Python Compatibility
- ‚úÖ Python 3.8+
- ‚úÖ Compatible con FastAPI
- ‚úÖ Compatible con Celery
- ‚úÖ Compatible con Redis (opcional)

## üêõ Soluci√≥n de Problemas

### Error: "Cliente OpenAI no inicializado"
```python
# Verificar que la API key est√© configurada
import os
print(f"API Key configurada: {bool(os.getenv('OPENAI_API_KEY'))}")

# Usar fallback local
analyzer = create_ai_processor()  # Sin API key
```

### Error: "Rate limit alcanzado"
```python
# El sistema esperar√° autom√°ticamente
# Para configurar l√≠mites m√°s altos:
analyzer = create_ai_processor(
    requests_per_minute=100,
    requests_per_day=50000
)
```

### Costos altos
```python
# Usar modelo m√°s econ√≥mico
analyzer = create_ai_processor(
    default_model="gpt-3.5-turbo"
)

# Aumentar cache TTL
analyzer = create_ai_processor(
    cache_ttl=7200  # 2 horas
)
```

## üìû Soporte

Para problemas o preguntas:

1. **Logs**: Revisar logs detallados del sistema
2. **Tests**: Ejecutar `test_ai_processor.py` para verificar funcionalidad
3. **Ejemplos**: Revisar `examples_ai_processor.py` para casos de uso
4. **Configuraci√≥n**: Verificar variables de entorno y configuraci√≥n

## üéâ Conclusi√≥n

El AI Processor Service proporciona una soluci√≥n robusta, escalable y eficiente para el an√°lisis inteligente de noticias. Con caracter√≠sticas avanzadas como rate limiting, retry logic, optimizaci√≥n de costos y fallbacks, est√° dise√±ado para uso en producci√≥n con alta confiabilidad.