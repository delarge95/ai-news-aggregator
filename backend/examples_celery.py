"""
Ejemplo pr√°ctico de uso del sistema Celery para AI News Aggregator
Demuestra todas las funcionalidades implementadas
"""

import time
import json
from typing import List, Dict, Any
from loguru import logger

# Importar tareas de Celery
from app.tasks import (
    analyze_article_async,
    batch_analyze_articles,
    classify_topics_batch,
    generate_summaries_batch,
    fetch_latest_news,
    search_news_task,
    get_system_metrics,
    generate_article_digest
)

# Configurar logging
logger.add("logs/celery_example.log", rotation="10 MB", level="INFO")


class CeleryExampleRunner:
    """Ejecutor de ejemplos pr√°cticos del sistema Celery"""
    
    def __init__(self):
        self.results = {}
        
    def run_all_examples(self):
        """Ejecutar todos los ejemplos de uso"""
        logger.info("üöÄ Iniciando ejemplos completos del sistema Celery")
        
        # Ejemplo 1: Obtener noticias
        self.example_fetch_news()
        
        # Ejemplo 2: Analizar art√≠culo individual
        if self.results.get('news_articles'):
            self.example_analyze_single_article()
        
        # Ejemplo 3: Procesamiento en lote
        if self.results.get('news_articles'):
            self.example_batch_analysis()
        
        # Ejemplo 4: Clasificaci√≥n tem√°tica
        if self.results.get('analyzed_articles'):
            self.example_topic_classification()
        
        # Ejemplo 5: Generaci√≥n de res√∫menes
        if self.results.get('classified_articles'):
            self.example_generate_summaries()
        
        # Ejemplo 6: Digest consolidado
        if self.results.get('summaries'):
            self.example_generate_digest()
        
        # Ejemplo 7: B√∫squeda de noticias
        self.example_search_news()
        
        # Ejemplo 8: M√©tricas del sistema
        self.example_system_metrics()
        
        # Mostrar resumen final
        self.show_final_summary()
    
    def example_fetch_news(self):
        """Ejemplo 1: Obtener las √∫ltimas noticias"""
        logger.info("üì∞ Ejemplo 1: Obteniendo √∫ltimas noticias...")
        
        try:
            # Enviar tarea para obtener noticias
            result = fetch_latest_news.delay(
                limit_per_source=10,
                client_types=['newsapi']  # Usar solo NewsAPI para el ejemplo
            )
            
            # Esperar resultado
            news_data = result.get(timeout=300)  # 5 minutos timeout
            
            if news_data['status'] == 'success':
                articles = news_data['articles']
                self.results['news_articles'] = articles[:5]  # Solo los primeros 5
                
                logger.info(f"‚úÖ Obtenidas {len(articles)} noticias")
                logger.info(f"üìä Fuentes utilizadas: {news_data['statistics']['sources_used']}")
                logger.info(f"‚è±Ô∏è Tiempo de procesamiento: {news_data['statistics']['processing_time']:.2f}s")
                
                # Mostrar primeras noticias
                for i, article in enumerate(articles[:3], 1):
                    logger.info(f"   {i}. {article.get('title', 'Sin t√≠tulo')[:80]}...")
                    
            else:
                logger.error(f"‚ùå Error obteniendo noticias: {news_data.get('error_message')}")
                self.results['news_articles'] = []
                
        except Exception as e:
            logger.error(f"üí• Excepci√≥n en ejemplo de noticias: {str(e)}")
            self.results['news_articles'] = []
    
    def example_analyze_single_article(self):
        """Ejemplo 2: Analizar un art√≠culo individual"""
        logger.info("üîç Ejemplo 2: Analizando art√≠culo individual...")
        
        try:
            articles = self.results.get('news_articles', [])
            if not articles:
                logger.warning("‚ö†Ô∏è No hay art√≠culos para analizar")
                return
            
            # Seleccionar primer art√≠culo
            article = articles[0]
            
            # Enviar tarea de an√°lisis
            result = analyze_article_async.delay(article, 'comprehensive')
            
            # Esperar resultado
            analysis = result.get(timeout=180)  # 3 minutos timeout
            
            if analysis.get('status') == 'completed':
                self.results['single_analysis'] = analysis
                
                logger.info(f"‚úÖ An√°lisis completado")
                logger.info(f"üìù Categor√≠a: {analysis.get('category', 'N/A')}")
                logger.info(f"üè∑Ô∏è Temas: {analysis.get('topics', [])}")
                logger.info(f"üí≠ Sentimiento: {analysis.get('sentiment', 'N/A')}")
                logger.info(f"‚ö° Tiempo de an√°lisis: {analysis.get('processing_time', 0):.2f}s")
                
            else:
                logger.error(f"‚ùå Error en an√°lisis: {analysis.get('error_message')}")
                
        except Exception as e:
            logger.error(f"üí• Excepci√≥n en an√°lisis individual: {str(e)}")
    
    def example_batch_analysis(self):
        """Ejemplo 3: Procesamiento en lote de art√≠culos"""
        logger.info("üìä Ejemplo 3: An√°lisis en lote...")
        
        try:
            articles = self.results.get('news_articles', [])
            if len(articles) < 3:
                logger.warning("‚ö†Ô∏è Necesitamos al menos 3 art√≠culos para el lote")
                return
            
            # Seleccionar 3 art√≠culos para el ejemplo
            batch_articles = articles[:3]
            
            # Enviar tarea de an√°lisis en lote
            result = batch_analyze_articles.delay(
                batch_articles,
                analysis_type='comprehensive',
                batch_size=2,  # Procesar de 2 en 2
                max_workers=2
            )
            
            # Esperar resultado
            batch_result = result.get(timeout=600)  # 10 minutos timeout
            
            if batch_result.get('status') == 'completed':
                self.results['batch_analysis'] = batch_result
                
                logger.info(f"‚úÖ An√°lisis en lote completado")
                logger.info(f"üìä Procesados: {batch_result.get('total_processed', 0)}")
                logger.info(f"‚ùå Fallidos: {batch_result.get('total_failed', 0)}")
                logger.info(f"üìà Tasa de √©xito: {batch_result.get('success_rate', 0):.1f}%")
                logger.info(f"‚è±Ô∏è Tiempo total: {batch_result.get('processing_time', 0):.2f}s")
                
                # Mostrar resultados detallados si est√°n disponibles
                if 'successful_results' in batch_result:
                    for i, result in enumerate(batch_result['successful_results'], 1):
                        logger.info(f"   {i}. {result.get('category', 'N/A')} - {result.get('topics', [])[:2]}")
                        
            else:
                logger.error(f"‚ùå Error en an√°lisis en lote: {batch_result.get('error_message')}")
                
        except Exception as e:
            logger.error(f"üí• Excepci√≥n en an√°lisis en lote: {str(e)}")
    
    def example_topic_classification(self):
        """Ejemplo 4: Clasificaci√≥n tem√°tica"""
        logger.info("üè∑Ô∏è Ejemplo 4: Clasificaci√≥n tem√°tica...")
        
        try:
            articles = self.results.get('news_articles', [])
            if not articles:
                logger.warning("‚ö†Ô∏è No hay art√≠culos para clasificar")
                return
            
            # Enviar tarea de clasificaci√≥n
            result = classify_topics_batch.delay(
                articles,
                classification_system='comprehensive',
                min_confidence=0.5,
                max_categories_per_article=3
            )
            
            # Esperar resultado
            classification = result.get(timeout=300)  # 5 minutos timeout
            
            if classification.get('status') == 'completed':
                self.results['classified_articles'] = classification.get('classification_results', [])
                
                logger.info(f"‚úÖ Clasificaci√≥n completada")
                logger.info(f"üìä Art√≠culos clasificados: {classification.get('statistics', {}).get('classified_articles', 0)}")
                
                # Mostrar distribuci√≥n de temas
                topic_dist = classification.get('topic_distribution', {})
                if topic_dist:
                    logger.info("üìà Distribuci√≥n de temas:")
                    for topic, count in sorted(topic_dist.items(), key=lambda x: x[1], reverse=True):
                        logger.info(f"   {topic}: {count} art√≠culos")
                
            else:
                logger.error(f"‚ùå Error en clasificaci√≥n: {classification.get('error_message')}")
                
        except Exception as e:
            logger.error(f"üí• Excepci√≥n en clasificaci√≥n: {str(e)}")
    
    def example_generate_summaries(self):
        """Ejemplo 5: Generaci√≥n de res√∫menes"""
        logger.info("üìù Ejemplo 5: Generando res√∫menes...")
        
        try:
            articles = self.results.get('news_articles', [])
            if not articles:
                logger.warning("‚ö†Ô∏è No hay art√≠culos para resumir")
                return
            
            # Enviar tarea de generaci√≥n de res√∫menes
            result = generate_summaries_batch.delay(
                articles,
                summary_type='executive',
                max_summary_length=150,
                include_key_points=True
            )
            
            # Esperar resultado
            summaries = result.get(timeout=450)  # 7.5 minutos timeout
            
            if summaries.get('status') == 'completed':
                self.results['summaries'] = summaries.get('successful_summaries', [])
                
                logger.info(f"‚úÖ Res√∫menes generados")
                logger.info(f"üìù Art√≠culos resumidos: {summaries.get('statistics', {}).get('processed_articles', 0)}")
                logger.info(f"‚è±Ô∏è Tiempo promedio: {summaries.get('statistics', {}).get('avg_summary_length', 0):.1f} caracteres")
                
                # Mostrar algunos res√∫menes
                if self.results['summaries']:
                    for i, summary in enumerate(self.results['summaries'][:3], 1):
                        logger.info(f"   {i}. {summary.get('summary', '')[:100]}...")
                        
            else:
                logger.error(f"‚ùå Error en generaci√≥n de res√∫menes: {summaries.get('error_message')}")
                
        except Exception as e:
            logger.error(f"üí• Excepci√≥n en generaci√≥n de res√∫menes: {str(e)}")
    
    def example_generate_digest(self):
        """Ejemplo 6: Generar digest consolidado"""
        logger.info("üìã Ejemplo 6: Generando digest diario...")
        
        try:
            articles = self.results.get('news_articles', [])
            if not articles:
                logger.warning("‚ö†Ô∏è No hay art√≠culos para el digest")
                return
            
            # Enviar tarea de digest
            result = generate_article_digest.delay(
                articles,
                digest_type='daily',
                max_articles=10
            )
            
            # Esperar resultado
            digest = result.get(timeout=300)  # 5 minutos timeout
            
            if digest.get('status') == 'success':
                self.results['digest'] = digest.get('digest', '')
                
                logger.info(f"‚úÖ Digest generado")
                logger.info(f"üìä Art√≠culos incluidos: {digest.get('articles_included', 0)}")
                
                # Mostrar primeras l√≠neas del digest
                digest_lines = digest.get('digest', '').split('\n')[:10]
                logger.info("üìã Primeras l√≠neas del digest:")
                for line in digest_lines:
                    if line.strip():
                        logger.info(f"   {line}")
                        
            else:
                logger.error(f"‚ùå Error generando digest: {digest.get('error_message')}")
                
        except Exception as e:
            logger.error(f"üí• Excepci√≥n generando digest: {str(e)}")
    
    def example_search_news(self):
        """Ejemplo 7: B√∫squeda de noticias"""
        logger.info("üîç Ejemplo 7: Buscando noticias sobre IA...")
        
        try:
            # Enviar tarea de b√∫squeda
            result = search_news_task.delay(
                query='artificial intelligence',
                limit=5,
                client_types=['newsapi'],
                sort_by='relevance'
            )
            
            # Esperar resultado
            search_results = result.get(timeout=180)  # 3 minutos timeout
            
            if search_results.get('status') == 'success':
                self.results['search_results'] = search_results.get('articles', [])
                
                logger.info(f"‚úÖ B√∫squeda completada")
                logger.info(f"üîç Query: {search_results.get('query', '')}")
                logger.info(f"üìä Resultados encontrados: {search_results.get('total_results', 0)}")
                logger.info(f"‚è±Ô∏è Tiempo de b√∫squeda: {search_results.get('statistics', {}).get('processing_time', 0):.2f}s")
                
                # Mostrar resultados
                for i, article in enumerate(search_results.get('articles', [])[:3], 1):
                    logger.info(f"   {i}. {article.get('title', 'Sin t√≠tulo')[:80]}...")
                    
            else:
                logger.error(f"‚ùå Error en b√∫squeda: {search_results.get('error_message')}")
                
        except Exception as e:
            logger.error(f"üí• Excepci√≥n en b√∫squeda: {str(e)}")
    
    def example_system_metrics(self):
        """Ejemplo 8: M√©tricas del sistema"""
        logger.info("üìä Ejemplo 8: Obteniendo m√©tricas del sistema...")
        
        try:
            # Enviar tarea de m√©tricas
            result = get_system_metrics.delay()
            
            # Esperar resultado
            metrics = result.get(timeout=60)  # 1 minuto timeout
            
            if metrics.get('status') == 'success':
                self.results['metrics'] = metrics.get('metrics', {})
                
                # Mostrar m√©tricas principales
                celery_metrics = self.results['metrics'].get('celery_metrics', {})
                system_metrics = self.results['metrics'].get('system_metrics', {})
                redis_metrics = self.results['metrics'].get('redis_metrics', {})
                
                logger.info(f"‚úÖ M√©tricas obtenidas")
                logger.info(f"üë• Workers activos: {celery_metrics.get('active_workers', 0)}")
                logger.info(f"üìã Tareas activas: {celery_metrics.get('active_tasks_count', 0)}")
                logger.info(f"üíª CPU: {system_metrics.get('cpu_percent', 0):.1f}%")
                logger.info(f"üß† Memoria: {system_metrics.get('memory_percent', 0):.1f}%")
                logger.info(f"üíæ Redis memoria: {redis_metrics.get('used_memory_human', 'N/A')}")
                
            else:
                logger.error(f"‚ùå Error obteniendo m√©tricas: {metrics.get('error_message')}")
                
        except Exception as e:
            logger.error(f"üí• Excepci√≥n obteniendo m√©tricas: {str(e)}")
    
    def show_final_summary(self):
        """Mostrar resumen final de todos los ejemplos"""
        logger.info("üìä RESUMEN FINAL DE EJEMPLOS")
        logger.info("=" * 50)
        
        # Contar resultados exitosos
        successful_examples = 0
        total_examples = 8
        
        if self.results.get('news_articles'):
            successful_examples += 1
            logger.info(f"‚úÖ 1. Noticias obtenidas: {len(self.results['news_articles'])} art√≠culos")
        
        if self.results.get('single_analysis'):
            successful_examples += 1
            logger.info(f"‚úÖ 2. An√°lisis individual: {self.results['single_analysis'].get('category', 'N/A')}")
        
        if self.results.get('batch_analysis'):
            successful_examples += 1
            batch_stats = self.results['batch_analysis']
            logger.info(f"‚úÖ 3. An√°lisis en lote: {batch_stats.get('total_processed', 0)} art√≠culos")
        
        if self.results.get('classified_articles'):
            successful_examples += 1
            logger.info(f"‚úÖ 4. Clasificaci√≥n tem√°tica: {len(self.results['classified_articles'])} art√≠culos")
        
        if self.results.get('summaries'):
            successful_examples += 1
            logger.info(f"‚úÖ 5. Res√∫menes generados: {len(self.results['summaries'])} res√∫menes")
        
        if self.results.get('digest'):
            successful_examples += 1
            logger.info(f"‚úÖ 6. Digest consolidado: Generado")
        
        if self.results.get('search_results'):
            successful_examples += 1
            logger.info(f"‚úÖ 7. B√∫squeda de noticias: {len(self.results['search_results'])} resultados")
        
        if self.results.get('metrics'):
            successful_examples += 1
            logger.info(f"‚úÖ 8. M√©tricas del sistema: Obtenidas")
        
        logger.info(f"üìà Tasa de √©xito: {successful_examples}/{total_examples} ({(successful_examples/total_examples)*100:.1f}%)")
        
        if successful_examples == total_examples:
            logger.info("üéâ ¬°Todos los ejemplos ejecutados exitosamente!")
        elif successful_examples > total_examples // 2:
            logger.info("üëç La mayor√≠a de ejemplos completados correctamente")
        else:
            logger.warning("‚ö†Ô∏è Varios ejemplos fallaron - revisar configuraci√≥n")
        
        # Guardar resultados en archivo
        self.save_results_to_file()
    
    def save_results_to_file(self):
        """Guardar resultados en archivo JSON"""
        try:
            output_file = "logs/celery_examples_results.json"
            
            # Preparar datos serializables
            serializable_results = {}
            for key, value in self.results.items():
                if key == 'digest':
                    # Guardar solo texto del digest
                    serializable_results[key] = value
                elif isinstance(value, (str, int, float, bool, list, dict)):
                    serializable_results[key] = value
                else:
                    # Para objetos complejos, convertir a string
                    serializable_results[key] = str(value)
            
            with open(output_file, 'w', encoding='utf-8') as f:
                json.dump(serializable_results, f, indent=2, ensure_ascii=False)
            
            logger.info(f"üíæ Resultados guardados en: {output_file}")
            
        except Exception as e:
            logger.error(f"üí• Error guardando resultados: {str(e)}")


def main():
    """Funci√≥n principal para ejecutar los ejemplos"""
    print("üöÄ AI News Aggregator - Ejemplos de Celery")
    print("=" * 50)
    print("Este script demuestra todas las funcionalidades del sistema Celery")
    print("Aseg√∫rate de que Redis y los workers de Celery est√©n ejecut√°ndose")
    print("=" * 50)
    
    # Crear directorio de logs si no existe
    import os
    os.makedirs("logs", exist_ok=True)
    
    # Ejecutar ejemplos
    runner = CeleryExampleRunner()
    runner.run_all_examples()
    
    print("\nüéâ Ejemplos completados. Revisa los logs para m√°s detalles.")


if __name__ == "__main__":
    main()