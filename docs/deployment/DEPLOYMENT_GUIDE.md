# Gu√≠a de Deployment - AI News Aggregator

## Tabla de Contenidos
- [Prerequisites](#prerequisites)
- [Arquitectura del Sistema](#arquitectura-del-sistema)
- [Configuraci√≥n de Entorno](#configuraci√≥n-de-entorno)
- [Deployment por Fases](#deployment-por-fases)
- [Verificaci√≥n Post-Deployment](#verificaci√≥n-post-deployment)
- [Rollback](#rollback)
- [Monitoreo](#monitoreo)

## Prerequisites

### Herramientas Requeridas
```bash
# Instalar herramientas b√°sicas
curl -fsSL https://get.docker.com/ | sh
sudo apt-get update
sudo apt-get install -y git make docker-compose nginx certbot python3-certbot-nginx

# Verificar instalaci√≥n
docker --version
docker-compose --version
nginx -v
```

### Cuentas y Servicios
- [ ] DigitalOcean Account (Droplets, Managed Databases, Load Balancers)
- [ ] Cloudflare (DNS y SSL)
- [ ] SendGrid (Email notifications)
- [ ] New York Times API Key
- [ ] Guardian API Key
- [ ] NewsAPI Key

## Arquitectura del Sistema

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   Nginx         ‚îÇ    ‚îÇ   Frontend      ‚îÇ    ‚îÇ   Load Balancer ‚îÇ
‚îÇ   (Reverse      ‚îÇ    ‚îÇ   (React/Vite)  ‚îÇ    ‚îÇ   (DigitalOcean)‚îÇ
‚îÇ    Proxy)       ‚îÇ    ‚îÇ                 ‚îÇ    ‚îÇ                 ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
          ‚îÇ                      ‚îÇ                      ‚îÇ
          ‚îÇ              ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê              ‚îÇ
          ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§ API Gateway    ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                         ‚îÇ (Nginx)        ‚îÇ
                         ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                 ‚îÇ
          ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
          ‚îÇ                      ‚îÇ                      ‚îÇ
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   Backend       ‚îÇ    ‚îÇ   Redis         ‚îÇ    ‚îÇ   Celery        ‚îÇ
‚îÇ   (FastAPI)     ‚îÇ    ‚îÇ   (Cache)       ‚îÇ    ‚îÇ   (Tasks)       ‚îÇ
‚îÇ   Port: 8000    ‚îÇ    ‚îÇ   Port: 6379    ‚îÇ    ‚îÇ   Port: 5555    ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
          ‚îÇ                      ‚îÇ                      ‚îÇ
          ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                 ‚îÇ
                     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                     ‚îÇ   PostgreSQL          ‚îÇ
                     ‚îÇ   (Managed Database)  ‚îÇ
                     ‚îÇ   Port: 5432          ‚îÇ
                     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

## Configuraci√≥n de Entorno

### 1. Variables de Entorno

Crear archivo `.env` en la ra√≠z del proyecto:

```bash
# ==============================================
# AI NEWS AGGREGATOR - PRODUCTION ENVIRONMENT
# ==============================================

# Application Settings
ENVIRONMENT=production
DEBUG=false
LOG_LEVEL=INFO
SECRET_KEY=your-super-secret-key-here

# Database Configuration
DATABASE_URL=postgresql://username:password@host:5432/database
POSTGRES_DB=ai_news_aggregator
POSTGRES_USER=your_db_user
POSTGRES_PASSWORD=your_db_password
POSTGRES_HOST=your_db_host
POSTGRES_PORT=5432

# Redis Configuration
REDIS_URL=redis://username:password@host:6379
REDIS_HOST=your_redis_host
REDIS_PORT=6379
REDIS_PASSWORD=your_redis_password

# API Keys
NEWSAPI_KEY=your_newsapi_key
NYTIMES_API_KEY=your_nytimes_api_key
GUARDIAN_API_KEY=your_guardian_api_key

# AI Configuration
OPENAI_API_KEY=your_openai_api_key
AI_MODEL=gpt-3.5-turbo
AI_MAX_TOKENS=1000
AI_TEMPERATURE=0.7

# Email Configuration
SMTP_HOST=smtp.sendgrid.net
SMTP_PORT=587
SMTP_USERNAME=apikey
SMTP_PASSWORD=your_sendgrid_api_key
EMAIL_FROM=noreply@yourdomain.com

# Security Settings
ALLOWED_HOSTS=yourdomain.com,www.yourdomain.com
CORS_ORIGINS=https://yourdomain.com
JWT_SECRET_KEY=your-jwt-secret-key
JWT_ALGORITHM=HS256
JWT_EXPIRATION_HOURS=24

# Rate Limiting
RATE_LIMIT_PER_MINUTE=100
RATE_LIMIT_PER_HOUR=1000

# Performance Settings
WORKERS=4
MAX_CONNECTIONS=100
TIMEOUT=30

# Monitoring
SENTRY_DSN=your_sentry_dsn
PROMETHEUS_ENABLED=true
GRAFANA_ADMIN_PASSWORD=your_grafana_password

# Backup Configuration
BACKUP_S3_BUCKET=your-backup-bucket
AWS_ACCESS_KEY_ID=your_aws_access_key
AWS_SECRET_ACCESS_KEY=your_aws_secret_key
```

### 2. Configuraci√≥n de Nginx

Crear `/etc/nginx/sites-available/ai-news-aggregator`:

```nginx
server {
    listen 80;
    server_name yourdomain.com www.yourdomain.com;
    return 301 https://$server_name$request_uri;
}

server {
    listen 443 ssl http2;
    server_name yourdomain.com www.yourdomain.com;

    # SSL Configuration
    ssl_certificate /etc/letsencrypt/live/yourdomain.com/fullchain.pem;
    ssl_certificate_key /etc/letsencrypt/live/yourdomain.com/privkey.pem;
    
    # Security Headers
    add_header Strict-Transport-Security "max-age=31536000; includeSubDomains" always;
    add_header X-Content-Type-Options nosniff always;
    add_header X-Frame-Options DENY always;
    add_header X-XSS-Protection "1; mode=block" always;
    add_header Referrer-Policy "strict-origin-when-cross-origin" always;

    # Gzip Compression
    gzip on;
    gzip_vary on;
    gzip_min_length 10240;
    gzip_proxied expired no-cache no-store private must-revalidate auth;
    gzip_types
        text/plain
        text/css
        text/xml
        text/javascript
        application/javascript
        application/xml+rss
        application/json;

    # Rate Limiting
    limit_req_zone $binary_remote_addr zone=api:10m rate=10r/s;
    limit_req_zone $binary_remote_addr zone=auth:10m rate=1r/s;

    # Frontend (React App)
    location / {
        root /var/www/ai-news-aggregator/frontend;
        try_files $uri $uri/ /index.html;
        
        # Cache static assets
        location ~* \.(js|css|png|jpg|jpeg|gif|ico|svg|woff|woff2|ttf|eot)$ {
            expires 1y;
            add_header Cache-Control "public, immutable";
        }
    }

    # API Routes
    location /api/ {
        limit_req zone=api burst=20 nodelay;
        
        proxy_pass http://localhost:8000;
        proxy_http_version 1.1;
        proxy_set_header Upgrade $http_upgrade;
        proxy_set_header Connection 'upgrade';
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
        proxy_set_header X-Forwarded-Proto $scheme;
        proxy_cache_bypass $http_upgrade;
        
        # Timeouts
        proxy_connect_timeout 60s;
        proxy_send_timeout 60s;
        proxy_read_timeout 60s;
    }

    # Auth endpoints with stricter limits
    location /api/auth/ {
        limit_req zone=auth burst=5 nodelay;
        
        proxy_pass http://localhost:8000;
        proxy_http_version 1.1;
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
        proxy_set_header X-Forwarded-Proto $scheme;
    }

    # Celery Flower monitoring
    location /flower/ {
        proxy_pass http://localhost:5555;
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
        proxy_set_header X-Forwarded-Proto $scheme;
        
        # Basic Auth for Flower
        auth_basic "Celery Monitor";
        auth_basic_user_file /etc/nginx/.htpasswd;
    }

    # Health check endpoint
    location /health {
        proxy_pass http://localhost:8000/health;
        access_log off;
    }

    # Security
    location ~ /\. {
        deny all;
        access_log off;
        log_not_found off;
    }

    location ~ ~$ {
        deny all;
        access_log off;
        log_not_found off;
    }
}
```

## Deployment por Fases

### Fase 1: Preparaci√≥n del Servidor

```bash
# 1. Conectar al servidor
ssh root@your-server-ip

# 2. Actualizar sistema
apt update && apt upgrade -y

# 3. Crear usuario no-root
adduser deploy
usermod -aG sudo deploy
usermod -aG docker deploy

# 4. Configurar firewall
ufw default deny incoming
ufw default allow outgoing
ufw allow ssh
ufw allow 80
ufw allow 443
ufw enable

# 5. Instalar Docker
curl -fsSL https://get.docker.com/ | sh
systemctl enable docker
usermod -aG docker deploy

# 6. Configurar SSH keys (recomendado)
mkdir -p /home/deploy/.ssh
cp your-public-key.pub /home/deploy/.ssh/authorized_keys
chmod 700 /home/deploy/.ssh
chmod 600 /home/deploy/.ssh/authorized_keys
chown -R deploy:deploy /home/deploy/.ssh

# 7. Deshabilitar password authentication
sed -i 's/#PasswordAuthentication yes/PasswordAuthentication no/' /etc/ssh/sshd_config
systemctl reload sshd
```

### Fase 2: Configuraci√≥n de Infraestructura

```bash
# 1. Crear directorios del proyecto
sudo mkdir -p /var/www/ai-news-aggregator
sudo chown deploy:deploy /var/www/ai-news-aggregator
cd /var/www/ai-news-aggregator

# 2. Clonar repositorio
git clone https://github.com/yourusername/ai-news-aggregator.git .
git checkout production

# 3. Configurar variables de entorno
cp .env.example .env
nano .env  # Editar con valores reales

# 4. Configurar permisos
chmod +x start.sh
chmod +x backend/start_celery.sh
```

### Fase 3: Build y Deploy

```bash
# 1. Build de im√°genes Docker
make build

# 2. Ejecutar migraciones de base de datos
make migrate

# 3. Iniciar servicios
make up

# 4. Verificar estado de contenedores
make ps

# 5. Ejecutar health checks
make health-check
```

### Fase 4: SSL y Dominio

```bash
# 1. Instalar certbot
apt install -y certbot python3-certbot-nginx

# 2. Obtener certificado SSL
certbot --nginx -d yourdomain.com -d www.yourdomain.com

# 3. Configurar renovaci√≥n autom√°tica
crontab -e
# Agregar: 0 12 * * * /usr/bin/certbot renew --quiet
```

## Verificaci√≥n Post-Deployment

### Health Checks Autom√°ticos

```bash
#!/bin/bash
# health-check.sh

echo "üîç Verificando servicios..."

# 1. Verificar contenedores
if docker-compose ps | grep -q "Up"; then
    echo "‚úÖ Contenedores ejecut√°ndose"
else
    echo "‚ùå Error en contenedores"
    exit 1
fi

# 2. Verificar conectividad a base de datos
if docker exec ai-news-aggregator-backend python -c "import psycopg2; psycopg2.connect('$DATABASE_URL').close()"; then
    echo "‚úÖ Base de datos conectada"
else
    echo "‚ùå Error conectando a base de datos"
    exit 1
fi

# 3. Verificar API endpoints
if curl -f http://localhost/api/health > /dev/null 2>&1; then
    echo "‚úÖ API respondiendo"
else
    echo "‚ùå API no responde"
    exit 1
fi

# 4. Verificar Redis
if docker exec ai-news-aggregator-redis redis-cli ping | grep -q PONG; then
    echo "‚úÖ Redis conectado"
else
    echo "‚ùå Error conectando a Redis"
    exit 1
fi

# 5. Verificar Celery
if docker exec ai-news-aggregator-backend python -c "from celery_app import app; print(app.control.inspect().active())" > /dev/null 2>&1; then
    echo "‚úÖ Celery ejecut√°ndose"
else
    echo "‚ùå Error con Celery"
    exit 1
fi

echo "‚úÖ Todos los servicios est√°n funcionando correctamente"
```

### Tests Post-Deployment

```bash
# 1. Ejecutar tests de integraci√≥n
make test-integration

# 2. Verificar performance
make test-performance

# 3. Verificar cobertura de c√≥digo
make test-coverage

# 4. Verificar funcionalidades clave
./verify_testing_setup.sh
```

## Rollback

### Rollback Autom√°tico

```bash
#!/bin/bash
# rollback.sh

echo "üîÑ Iniciando rollback..."

# 1. Hacer backup del estado actual
make backup

# 2. Parar servicios actuales
make down

# 3. Revertir a versi√≥n anterior
git checkout previous-stable-tag

# 4. Rebuild con versi√≥n anterior
make build
make migrate
make up

# 5. Verificar rollback
./health-check.sh

echo "‚úÖ Rollback completado"
```

### Rollback Manual

```bash
# 1. Identificar problemas
make logs

# 2. Revertir cambios
git revert HEAD

# 3. Rebuild y redesplegar
make build-prod
make down
make up-prod

# 4. Verificar restauraci√≥n
make health-check
```

## Monitoreo

### M√©tricas Clave a Monitorear

1. **Performance**
   - Response time (p95 < 500ms)
   - Throughput (requests/second)
   - Error rate (< 1%)

2. **Infraestructura**
   - CPU usage (< 80%)
   - Memory usage (< 85%)
   - Disk usage (< 90%)
   - Network I/O

3. **Base de Datos**
   - Connection pool usage
   - Query execution time
   - Index efficiency
   - Replication lag

4. **Cache (Redis)**
   - Hit rate (> 90%)
   - Memory usage
   - Eviction rate
   - Connection count

### Configuraci√≥n de Alertas

```yaml
# alerts.yml
groups:
- name: ai-news-aggregator
  rules:
  - alert: HighErrorRate
    expr: rate(http_requests_total{status=~"5.."}[5m]) > 0.01
    for: 2m
    labels:
      severity: critical
    annotations:
      summary: High error rate detected
      description: "Error rate is {{ $value }} for {{ $labels.instance }}"

  - alert: DatabaseConnectionPoolExhausted
    expr: database_connections_active / database_connections_max > 0.9
    for: 1m
    labels:
      severity: warning
    annotations:
      summary: Database connection pool near exhaustion
```

### Logs Estructurados

```python
# Ejemplo de logging estructurado
import structlog

logger = structlog.get_logger()

# En el c√≥digo
logger.info(
    "API request processed",
    endpoint="/api/news",
    method="GET",
    status_code=200,
    response_time_ms=45.2,
    user_id=user.id if user else None
)
```

## Comandos √ötiles

```bash
# Gesti√≥n de servicios
make up              # Iniciar todos los servicios
make down            # Parar todos los servicios
make restart         # Reiniciar servicios
make logs            # Ver logs en tiempo real
make logs-backend    # Ver logs del backend
make logs-frontend   # Ver logs del frontend
make logs-celery     # Ver logs de Celery

# Base de datos
make migrate         # Ejecutar migraciones
make migrate-rollback # Revertir migraciones
make db-backup       # Backup de BD
make db-restore      # Restaurar BD

# Performance
make benchmark       # Ejecutar benchmarks
make profile         # Profiling de aplicaci√≥n
make optimize        # Optimizar BD

# Testing
make test            # Ejecutar todos los tests
make test-unit       # Tests unitarios
make test-integration # Tests de integraci√≥n
make test-e2e        # Tests end-to-end

# Monitoreo
make metrics         # Ver m√©tricas
make health          # Health check
make status          # Estado general del sistema
```

## Troubleshooting

Si encuentras problemas durante el deployment:

1. **Revisar logs**: `make logs`
2. **Verificar configuraci√≥n**: `make config-check`
3. **Validar base de datos**: `make db-check`
4. **Verificar conectividad**: `make network-check`
5. **Consultar troubleshooting**: Ver [TROUBLESHOOTING.md](./TROUBLESHOOTING.md)

## Pr√≥ximos Pasos

Una vez completado el deployment:

1. Configurar monitoreo avanzado (ver [MONITORING_SETUP.md](./MONITORING_SETUP.md))
2. Implementar security hardening (ver [SECURITY_CHECKLIST.md](./SECURITY_CHECKLIST.md))
3. Configurar backups automatizados (ver [BACKUP_RECOVERY.md](./BACKUP_RECOVERY.md))
4. Optimizar performance (ver [PERFORMANCE_TUNING.md](./PERFORMANCE_TUNING.md))

---

**Nota**: Esta gu√≠a asume un ambiente de producci√≥n en DigitalOcean. Para otros proveedores de cloud, ajustar las instrucciones seg√∫n corresponda.